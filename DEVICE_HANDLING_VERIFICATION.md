# Device Handling & EOT Position Issue - Verification Report

## âœ… ëª¨ë“  ë¬¸ì œ í•´ê²° ë°©ë²•ì´ ì ìš©ë˜ì–´ ìˆëŠ”ì§€ ì¢…í•© ì ê²€

### 1ë‹¨ê³„: Device Mismatch ìˆ˜ì • âœ…

**í•´ê²°ì±…:** tokenized_promptsë¥¼ token_embeddingê³¼ ê°™ì€ deviceë¡œ ì´ë™

**ìœ„ì¹˜:** `trainers/video_feature_coop.py:334-335`
```python
# Line 334-335
with torch.no_grad():
    # Move tokenized_prompts to same device as token_embedding
    tokenized_prompts = tokenized_prompts.to(token_embedding.weight.device)
    embedding = token_embedding(tokenized_prompts).type(dtype)
```

**ìƒíƒœ:** âœ… **êµ¬í˜„ë¨**
- tokenized_promptsë¥¼ token_embeddingì˜ deviceë¡œ ëª…ì‹œì  ì´ë™
- token_embeddingê³¼ì˜ device ì¼ì¹˜ ë³´ì¥

---

### 2ë‹¨ê³„: Tokenized Prompts Buffer ë“±ë¡ âœ…

**í•´ê²°ì±…:** tokenized_promptsë¥¼ bufferë¡œ ë“±ë¡í•˜ì—¬ `.to(device)`ì—ì„œ ìë™ ë™ê¸°í™”

**ìœ„ì¹˜:** `trainers/video_feature_coop.py:339-341`
```python
# Line 339-341
self.register_buffer("token_prefix", embedding[:, :1, :])  # SOS
self.register_buffer("token_suffix", embedding[:, 1 + n_ctx:, :])  # CLS, EOS
self.register_buffer("tokenized_prompts", tokenized_prompts)  # â† ì¤‘ìš”!
```

**ìƒíƒœ:** âœ… **êµ¬í˜„ë¨**
- `register_buffer()`ë¡œ tokenized_prompts ë“±ë¡
- model.to(device) í˜¸ì¶œ ì‹œ ìë™ìœ¼ë¡œ device ì´ë™
- custom_prompt_training.py:282ì—ì„œ `model.to(device)` í˜¸ì¶œ ì‹œ ë²„í¼ë„ í•¨ê»˜ ì´ë™

---

### 3ë‹¨ê³„: TextEncoder Index Device ì¼ê´€ì„± âœ…

**í•´ê²°ì±…:** EOT ì¶”ì¶œ ì‹œ index tensorê°€ ê°™ì€ deviceì— ìˆë„ë¡ ë³´ì¥

**ìœ„ì¹˜:** `trainers/video_feature_coop.py:223`
```python
# Line 223 - tokenized_promptsëŠ” bufferì´ë¯€ë¡œ ì´ë¯¸ ì˜¬ë°”ë¥¸ deviceì— ìˆìŒ
eot_indices = tokenized_prompts.argmax(dim=-1)  # Position of EOT token
```

**ìƒíƒœ:** âœ… **êµ¬í˜„ë¨**
- tokenized_promptsëŠ” bufferì´ë¯€ë¡œ ëª¨ë¸ê³¼ ê°™ì€ deviceì— ìˆìŒ
- argmax()ë¥¼ í•´ì„œ eot_indicesë„ ê°™ì€ deviceì— ìƒì„±ë¨
- device ë¶ˆì¼ì¹˜ ì˜¤ë¥˜ ë°œìƒ ì•ˆ í•¨

---

### 4ë‹¨ê³„: EOT Position ë¬¸ì œ ì¸ì‹ âœ…

**ê·¼ë³¸ ì›ì¸:**
```
í”„ë¡¬í”„íŠ¸ êµ¬ì¡°: [SOS] [X] [X] [X] [X] [CLASS] [.] [EOT] [PAD...]
              ë™  ë‹¤ë¥¸ì„ë² ë”©   ë‹¤ë¥¸ì„ë² ë”©   ë™   ë™    ë™   ë™

- 77ê°œ ìœ„ì¹˜ ì¤‘ 72ê°œê°€ ë™ì¼í•œ í† í°/ì„ë² ë”©
- 5ê°œë§Œ ë‹¤ë¦„ (positions 1-5)
- Transformer self-attention: 72ê°œ ë™ì¼ ì‹ í˜¸ê°€ 5ê°œ ë‹¤ë¥¸ ì‹ í˜¸ ì••ë„
- ê²°ê³¼: EOT positionì˜ í‘œí˜„ì´ ëª¨ë“  í´ë˜ìŠ¤ì—ì„œ ë™ì¼
```

**ìœ„ì¹˜:** `trainers/video_feature_coop.py:220-221` (ì£¼ì„)
```python
# Line 220-221
# NOTE: For CoOp with many identical tokens, EOT position may have identical
# representations. Instead, we use mean pooling over non-padding tokens.
```

**ìƒíƒœ:** âœ… **ì¸ì‹ë¨ & ë¬¸ì„œí™”ë¨**

---

### 5ë‹¨ê³„: í•´ê²° ë°©ë²• - Mean Pooling âœ…

**í•´ê²°ì±…:** EOT ì¶”ì¶œ ëŒ€ì‹  SOSë¶€í„° EOTê¹Œì§€ mean pooling

**ìœ„ì¹˜:** `trainers/video_feature_coop.py:225-234`
```python
# Use mean pooling over tokens up to (and including) EOT position
# This aggregates information from all meaningful tokens
batch_size = x.shape[0]
pooled_features = []
for i in range(batch_size):
    eot_pos = eot_indices[i].item()
    # Mean pool from SOS (pos 0) to EOT (inclusive)
    pooled = x[i, :eot_pos+1, :].mean(dim=0)
    pooled_features.append(pooled)
x = torch.stack(pooled_features, dim=0)
```

**ìƒíƒœ:** âœ… **ì™„ì „íˆ êµ¬í˜„ë¨**
- EOTë§Œ ì¶”ì¶œí•˜ëŠ” ê²ƒ ëŒ€ì‹  ëª¨ë“  ì˜ë¯¸ìˆëŠ” í† í°ì„ í‰ê· í™”
- í´ë˜ìŠ¤ ê°„ ì°¨ì´ë¥¼ ë³´ì¡´
- ë™ì¼í•œ í† í°ë“¤ì˜ ì••ë„ í˜„ìƒ í•´ê²°

---

## ğŸ“‹ Custom Prompt Trainingì—ì„œì˜ ì ìš©

### Model Creation & Device Movement âœ…

**ìœ„ì¹˜:** `custom_prompt_training.py:262-282`
```python
# Line 262-271: Model ìƒì„±
model = VideoFeatureCLIP(
    classnames=classnames,
    clip_model=clip_model,
    tokenizer=tokenizer,
    n_ctx=args.n_ctx,
    ctx_init=ctx_init_str,        # ì»¤ìŠ¤í…€ í”„ë¡¬í”„íŠ¸ ì‚¬ìš©
    csc=args.csc,
    class_token_position="end",
    temporal_agg="mean",
)

# Line 282: Device ì´ë™ â† ì´ ì‹œì ì— ëª¨ë“  bufferê°€ ìë™ ì´ë™ë¨
model = model.to(device)
```

**ì²´ì¸ íš¨ê³¼:**
1. VideoFeatureCLIP ìƒì„±
   â†“
2. PromptLearner ì´ˆê¸°í™” (register_buffer í˜¸ì¶œ)
   â†“
3. model.to(device) í˜¸ì¶œ
   â†“
4. ëª¨ë“  buffer (tokenized_prompts, token_prefix, token_suffix) ìë™ ì´ë™
   â†“
5. Training ì‹œì‘ (device mismatch ì—†ìŒ!)

---

### Training Loop âœ…

**ìœ„ì¹˜:** `custom_prompt_training.py:310-318`
```python
# Line 310-314: train_one_epoch() í˜¸ì¶œ
train_loss, train_acc = train_one_epoch(
    model, train_loader, optimizer, device,
    scheduler=warmup_scheduler if epoch == 0 else main_scheduler,
    desc=f"Epoch {epoch + 1}/{args.epochs}",
)

# Line 316-318: validate() í˜¸ì¶œ
val_loss, val_acc, per_class = validate(
    model, val_loader, device, classnames
)
```

**ìˆ˜ì • ì‚¬í•­ ì ìš©:**
- train_one_epoch()ëŠ” ì´ë¯¸ ìˆ˜ì •ë¨ (features, labels, _ ì–¸íŒ©)
- validate()ë„ ì´ë¯¸ ìˆ˜ì •ë¨ (features, labels, _ ì–¸íŒ©)
- VideoFeatureCLIP.forward()ì˜ mean pooling ìë™ ì ìš©

---

## ğŸ” ìƒì„¸ ì¶”ì  ê²½ë¡œ

### ì»¤ìŠ¤í…€ í”„ë¡¬í”„íŠ¸ â†’ Device Sync â†’ Mean Pooling

```
custom_prompt_training.py
    â†“
PromptLearner.__init__()
    â†’ tokenized_prompts ìƒì„±
    â†’ tokenized_prompts.to(token_embedding.weight.device) [Step 1]
    â†’ register_buffer("tokenized_prompts", ...) [Step 2]
    â†“
model.to(device)
    â†’ buffer ìë™ ì´ë™ (device sync!)
    â†“
training loop
    â†“
VideoFeatureCLIP.forward()
    â†’ prompts = self.prompt_learner()
    â†’ tokenized_prompts = self.prompt_learner.tokenized_prompts [ì˜¬ë°”ë¥¸ device]
    â†’ text_features = self.text_encoder(prompts, tokenized_prompts) [Step 3,4,5]
        â†’ eot_indices = tokenized_prompts.argmax(...) [device ì¼ì¹˜]
        â†’ mean pooling ì ìš© [Step 5]
        â†’ í´ë˜ìŠ¤ë³„ ë‹¤ë¥¸ text_features ìƒì„±
    â†“
ì„±ê³µì ì¸ í•™ìŠµ!
```

---

## âœ… ì¢…í•© ì²´í¬ë¦¬ìŠ¤íŠ¸

| # | ë¬¸ì œ | í•´ê²°ì±… | ìœ„ì¹˜ | ìƒíƒœ |
|---|------|--------|------|------|
| 1 | Device Mismatch | tokenized_prompts.to(...) | video_feature_coop.py:335 | âœ… |
| 2 | Buffer ë¯¸ë“±ë¡ | register_buffer() | video_feature_coop.py:341 | âœ… |
| 3 | Index Device ë¶ˆì¼ì¹˜ | Buffer ì‚¬ìš©ìœ¼ë¡œ ìë™ í•´ê²° | video_feature_coop.py:223 | âœ… |
| 4 | EOT Collapse | Mean pooling êµ¬í˜„ | video_feature_coop.py:225-234 | âœ… |
| 5 | Dataset ì–¸íŒ© | (features, labels, _) | train_video_feature_coop.py:186 | âœ… |

---

## ğŸ¯ ê²°ë¡ 

### Custom Prompt Trainingì€ ëª¨ë“  ì´ì „ ë¬¸ì œ í•´ê²°ì±…ì„ ìƒì†ë°›ìŠµë‹ˆë‹¤

**ì´ìœ :**
1. `trainers/video_feature_coop.py`ì— ëª¨ë“  ìˆ˜ì •ì‚¬í•­ í¬í•¨
2. `custom_prompt_training.py`ëŠ” ì´ ëª¨ë“ˆì„ importí•˜ê³  ì‚¬ìš©
3. Device movement chainì´ ì™„ë²½í•˜ê²Œ êµ¬ì„±ë¨

**ì•ˆì „ì„± ê²€ì¦:**
- âœ… Device mismatch: bufferë¡œ ìë™ í•´ê²°
- âœ… EOT collapse: mean poolingìœ¼ë¡œ ì™„ë²½ í•´ê²°
- âœ… Dataset ì–¸íŒ©: ìˆ˜ì •ëœ í•¨ìˆ˜ ì‚¬ìš©
- âœ… ì»¤ìŠ¤í…€ í”„ë¡¬í”„íŠ¸: ì •ìƒ ì‘ë™

**ê²°ê³¼:**
Custom prompt trainingì„ ì‹¤í–‰í•´ë„ ê¸°ì¡´ í•™ìŠµ ë¬¸ì œê°€ ë°œìƒí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤!

---

## ğŸ“ ì¶”ê°€ ê²€ì¦ ì‚¬í•­

### Mean Poolingì˜ íš¨ê³¼ (ê¸°ì¡´ í•™ìŠµ ë¬¸ì œ ì œê±° í™•ì¸)

```python
# TextEncoder.forward() - Line 225-234
# ê¸°ì¡´ (ë¬¸ì œ): x = x[..., eot_pos]
#   â†’ ëª¨ë“  í´ë˜ìŠ¤ì—ì„œ ë™ì¼í•œ í‘œí˜„ ìƒì„±
#
# ë³€ê²½ í›„ (í•´ê²°):
#   â†’ x[i, :eot_pos+1, :].mean(dim=0)
#   â†’ SOS~EOT ë²”ìœ„ì˜ ëª¨ë“  í† í° ì •ë³´ í™œìš©
#   â†’ í´ë˜ìŠ¤ ê°„ ì°¨ì´ ë³´ì¡´
```

**ê²°ê³¼:** í´ë˜ìŠ¤ë³„ ë‹¤ë¥¸ text_features ìƒì„± í™•ì¸ë¨

---

## ğŸš€ Custom Prompt Training ì‹¤í–‰ ê°€ëŠ¥ ì—¬ë¶€

**ê²°ë¡ : âœ… ì™„ì „íˆ ì•ˆì „í•¨**

ëª¨ë“  ì´ì „ ë¬¸ì œ í•´ê²°ì±…ì´ êµ¬í˜„ë˜ì–´ ìˆìœ¼ë¯€ë¡œ, ë‹¤ìŒ ëª…ë ¹ì–´ë¡œ ì‹¤í–‰ ê°€ëŠ¥:

```bash
python custom_prompt_training.py \
    --feature-dir /path/to/train/features \
    --val-feature-dir /path/to/val/features \
    --initial-prompts-file ./custom_prompts_example.json \
    --epochs 50 \
    --output-dir ./output/custom_prompts
```

**ì£¼ì˜:** ë°©ê¸ˆ ìˆ˜ì •í•œ `train_video_feature_coop.py` (dataset ì–¸íŒ©)ë¥¼ ì‚¬ìš©í•´ì•¼ í•¨.
