# CoOp ë¹„ë””ì˜¤ í”¼ì²˜ í”„ë¡¬í”„íŠ¸ ëŸ¬ë‹ - ì™„ì „ ê°€ì´ë“œ

## ğŸ“‹ ê°œìš”

ì´ í”„ë¡œì íŠ¸ëŠ” ì‚¬ì „ ì¶”ì¶œëœ ë¹„ë””ì˜¤ í”¼ì²˜ì™€ MobileCLIP S0 í…ìŠ¤íŠ¸ ì¸ì½”ë”ë¥¼ í™œìš©í•œ **CoOp (Context Optimization)** ê¸°ë°˜ í”„ë¡¬í”„íŠ¸ ëŸ¬ë‹ êµ¬í˜„ì…ë‹ˆë‹¤.

**ì£¼ìš” íŠ¹ì§•:**
- âœ… ì‚¬ì „ ì¶”ì¶œëœ ë¹„ë””ì˜¤ í”¼ì²˜ (.npy í˜•ì‹) ì§€ì›
- âœ… í´ë˜ìŠ¤ë³„ ì»¤ìŠ¤í…€ ì´ˆê¸° í”„ë¡¬í”„íŠ¸ ì§€ì›
- âœ… MobileCLIP S0 v1/v2 ëª¨ë‘ ì§€ì›
- âœ… í”„ë ˆì„ ë ˆë²¨ ë° ë¹„ë””ì˜¤ ë ˆë²¨ í‰ê°€
- âœ… Temporal Ground Truth ê¸°ë°˜ í‰ê°€
- âœ… TensorBoard í†µí•©

---

## ğŸ—‚ï¸ í”„ë¡œì íŠ¸ êµ¬ì¡°

```
CoOp/
â”œâ”€â”€ datasets/
â”‚   â””â”€â”€ video_features.py              # ë¹„ë””ì˜¤ í”¼ì²˜ ë°ì´í„°ì…‹ ë¡œë”
â”œâ”€â”€ trainers/
â”‚   â””â”€â”€ video_feature_coop.py          # CoOp ëª¨ë¸ (MobileCLIP S0 ê¸°ë°˜)
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ evaluate_coop_model.sh         # í‰ê°€ ìŠ¤í¬ë¦½íŠ¸
â”œâ”€â”€ train_video_feature_coop.py        # ë©”ì¸ í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸
â”œâ”€â”€ custom_prompt_training.py          # ì»¤ìŠ¤í…€ í”„ë¡¬í”„íŠ¸ í•™ìŠµ
â”œâ”€â”€ evaluate_video_feature_coop.py     # í‘œì¤€ í‰ê°€
â”œâ”€â”€ evaluate_with_temporal_gt.py       # Temporal GT í‰ê°€
â”œâ”€â”€ example_custom_prompt_workflow.py  # ì»¤ìŠ¤í…€ í”„ë¡¬í”„íŠ¸ ì˜ˆì œ
â”œâ”€â”€ custom_prompts_example.json        # í”„ë¡¬í”„íŠ¸ ì˜ˆì‹œ
â””â”€â”€ output/
    â””â”€â”€ video_feature_coop/            # í•™ìŠµ ê²°ê³¼
        â”œâ”€â”€ checkpoints/
        â”œâ”€â”€ tensorboard/
        â””â”€â”€ metrics.json
```

---

## ğŸš€ ë¹ ë¥¸ ì‹œì‘

### 1ë‹¨ê³„: ê¸°ë³¸ í•™ìŠµ

```bash
python train_video_feature_coop.py \
    --feature-dir /path/to/train/features \
    --val-feature-dir /path/to/val/features \
    --epochs 50 \
    --output-dir ./output/video_feature_coop
```

### 2ë‹¨ê³„: ì»¤ìŠ¤í…€ í”„ë¡¬í”„íŠ¸ë¡œ í•™ìŠµ (ì„ íƒ)

```bash
python custom_prompt_training.py \
    --feature-dir /path/to/train/features \
    --val-feature-dir /path/to/val/features \
    --initial-prompts-file ./custom_prompts_example.json \
    --epochs 50 \
    --output-dir ./output/custom_prompts_v1
```

### 3ë‹¨ê³„: í‰ê°€

```bash
# í‘œì¤€ í‰ê°€
python evaluate_video_feature_coop.py \
    --test-feature-dir /path/to/test/features \
    --checkpoint-path ./output/video_feature_coop/video_feature_coop_best.pth \
    --csc \
    --output-dir ./output/evaluation

# Temporal GT í‰ê°€ (ì–´ë…¸í…Œì´ì…˜ ìˆì„ ë•Œ)
python evaluate_with_temporal_gt.py \
    --test-feature-dir /path/to/test/features \
    --annotation-file ./annotation/Temporal_Anomaly_Annotation.txt \
    --checkpoint-path ./output/video_feature_coop/video_feature_coop_best.pth \
    --output-dir ./output/evaluation_temporal
```

---

## ğŸ“š ìƒì„¸ ê°€ì´ë“œ

### í•™ìŠµ

#### ê¸°ë³¸ CoOp í•™ìŠµ
ğŸ‘‰ [train_video_feature_coop.py](./train_video_feature_coop.py) ì§ì ‘ ì‹¤í–‰

**ì£¼ìš” í•˜ì´í¼íŒŒë¼ë¯¸í„°:**
- `--epochs`: í•™ìŠµ ì—í¬í¬ ìˆ˜ (ê¸°ë³¸: 50)
- `--lr`: í•™ìŠµë¥  (ê¸°ë³¸: 0.002)
- `--n-ctx`: ì»¨í…ìŠ¤íŠ¸ í† í° ê°œìˆ˜ (ê¸°ë³¸: 16)
- `--batch-size`: ë°°ì¹˜ í¬ê¸° (ê¸°ë³¸: 32)
- `--csc`: Class-Specific Context ì‚¬ìš© (ê¸°ë³¸: True)

**ì¶œë ¥:**
- `output/video_feature_coop/video_feature_coop_best.pth`: ìµœê³  ì„±ëŠ¥ ëª¨ë¸
- `output/video_feature_coop/tensorboard/`: TensorBoard ë¡œê·¸

#### ì»¤ìŠ¤í…€ í”„ë¡¬í”„íŠ¸ë¡œ í•™ìŠµ
ğŸ‘‰ [CUSTOM_PROMPT_TRAINING.md](./CUSTOM_PROMPT_TRAINING.md) ì°¸ê³ 

**ì›Œí¬í”Œë¡œìš°:**
1. í”„ë¡¬í”„íŠ¸ ì„¤ê³„ â†’ `custom_prompts.json`
2. í•™ìŠµ â†’ `custom_prompt_training.py`
3. ë¶„ì„ â†’ `learned_prompts.json` ê²€í† 

**ì˜ˆì œ:**
```bash
python example_custom_prompt_workflow.py \
    --feature-dir /path/to/train \
    --val-feature-dir /path/to/val \
    --epochs 50
```

---

### í‰ê°€

#### í‘œì¤€ í‰ê°€ (Frame/Video level)
ğŸ‘‰ [EVALUATION_GUIDE.md](./EVALUATION_GUIDE.md) ì°¸ê³ 

**ì¶œë ¥ ë©”íŠ¸ë¦­:**
- Frame-level Accuracy
- Video-level Accuracy
- Per-class Precision, Recall, F1
- Confusion Matrix
- ROC-AUC

#### Temporal Ground Truth í‰ê°€
ğŸ‘‰ [TEMPORAL_GT_EVALUATION.md](./TEMPORAL_GT_EVALUATION.md) ì°¸ê³ 

**í‰ê°€ ë ˆë²¨:**
1. **Multi-class**: 14ê°œ í´ë˜ìŠ¤ ë¶„ë¥˜ ì„±ëŠ¥
2. **Binary**: ì •ìƒ(0) vs ì´ìƒ(1) ì´ì§„ ë¶„ë¥˜
3. **Anomaly-only**: ì´ìƒ ìƒ˜í”Œì— ëŒ€í•œ ë‹¤ì¤‘ í´ë˜ìŠ¤ AUC

**ì–´ë…¸í…Œì´ì…˜ í˜•ì‹:**
```
Video_Name          Class        Event1_Start  Event1_End  Event2_Start  Event2_End
Abuse028_x264.mp4   Abuse        165           240         -1            -1
Arson011_x264.mp4   Arson        150           420         680           1267
```

#### ë¹ ë¥¸ í‰ê°€
ğŸ‘‰ [QUICKSTART_EVALUATION.md](./QUICKSTART_EVALUATION.md) ì°¸ê³ 

ê¸°ë³¸ ëª…ë ¹ì–´ì™€ ê²°ê³¼ í•´ì„ ë°©ë²•

---

## ğŸ”§ í•µì‹¬ ì»´í¬ë„ŒíŠ¸

### 1. datasets/video_features.py

**VideoFeatureDataset í´ë˜ìŠ¤**

```python
dataset = VideoFeatureDataset(
    feature_dir="/path/to/features",
    annotation_dir="/path/to/annotations",
    unit_duration=1,              # ìŠ¬ë¼ì´ë”© ìœˆë„ìš° í¬ê¸° (ì´ˆ)
    overlap_ratio=0.0,            # ìœˆë„ìš° ì˜¤ë²„ë© ë¹„ìœ¨
    strict_normal_sampling=True,  # ë¹„ì •ìƒ ë¹„ë””ì˜¤ì˜ ì´ë²¤íŠ¸ í›„ ì •ìƒ ìƒ˜í”Œ ì œê±°
    use_video_level_pooling=False # True: [T,D]â†’[D] mean pooling, False: ìŠ¬ë¼ì´ë”© ìœˆë„ìš°
)

# Returns: (feature_tensor [unit_duration, D], label_int, video_id)
feature, label, video_id = dataset[0]
```

**ì£¼ìš” ê¸°ëŠ¥:**
- í´ë˜ìŠ¤ ë””ë ‰í† ë¦¬ ìë™ ìŠ¤ìº”
- Annotation ê¸°ë°˜ ì´ë²¤íŠ¸ ì‹œê°„ êµ¬ê°„ ì²˜ë¦¬
- Strict normal filtering: ì´ìƒ ì´ë²¤íŠ¸ í›„ label=0 ìŠ¤ë‹ˆí« ì œê±°
- Video-level mean pooling ì§€ì›

### 2. trainers/video_feature_coop.py

**VideoFeatureCLIP ëª¨ë¸ êµ¬ì¡°**

```
Input: features [B, T, D]
  â†“
Temporal Aggregation (mean)
  â†“ [B, D]
L2 Normalize
  â†“ [B, D]
PromptLearner()
  â†“ prompts [n_cls, seq_len, ctx_dim]
TextEncoder()
  â†“ text_features [n_cls, D]
L2 Normalize
  â†“
Cosine Similarity + logit_scale
  â†“ logits [B, n_cls]
```

**í•µì‹¬ ìˆ˜ì •ì‚¬í•­:**
- **Mean Pooling ëŒ€ì‹  EOT ì¶”ì¶œ**: í…ìŠ¤íŠ¸ ì¸ì½”ë” ì¶œë ¥ì˜ í‰ê· ì„ ì‚¬ìš© (EOT ìœ„ì¹˜ collapse í•´ê²°)
- **Device ì¼ê´€ì„±**: tokenized_promptsë¥¼ bufferë¡œ ë“±ë¡í•˜ì—¬ ìë™ GPU ì´ë™
- **MobileCLIP v1/v2 ì§€ì›**: Safe attribute extractionë¡œ nested CustomTextCLIP êµ¬ì¡° ì²˜ë¦¬

### 3. train_video_feature_coop.py

**í•™ìŠµ ë£¨í”„**

```
1. ë°ì´í„° ë¡œë“œ
2. ëª¨ë¸ ì´ˆê¸°í™”
3. Optimizer ì„¤ì • (prompt_learnerë§Œ í•™ìŠµ)
4. LR Scheduler (Warmup + Cosine Annealing)
5. ë°˜ë³µ:
   - Forward pass
   - CrossEntropyLoss ê³„ì‚°
   - Backward pass (prompt_learnerë§Œ)
   - ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ ì €ì¥
6. TensorBoard ë¡œê·¸
```

**ì €ì¥ íŒŒì¼:**
- `checkpoints/best_model.pth`: ìµœê³  ê²€ì¦ ì •í™•ë„
- `checkpoints/video_feature_coop_final.pth`: ìµœì¢… ëª¨ë¸
- `checkpoints/video_feature_coop_ep*.pth`: ì£¼ê¸°ì  ì²´í¬í¬ì¸íŠ¸
- `tensorboard/events.out.tfevents.*`: TensorBoard ë¡œê·¸

### 4. custom_prompt_training.py

**ì»¤ìŠ¤í…€ í”„ë¡¬í”„íŠ¸ ì§€ì›**

```python
# ë°©ë²• 1: JSON íŒŒì¼
python custom_prompt_training.py \
    --initial-prompts-file ./my_prompts.json

# ë°©ë²• 2: ëª…ë ¹ì–´ ë¼ì¸
python custom_prompt_training.py \
    --custom-prompts Normal "a normal scene" Abuse "an attack"

# ë°©ë²• 3: ê¸°ë³¸ê°’ (ìë™ ìƒì„±)
python custom_prompt_training.py
```

**ì¶œë ¥:**
- `initial_prompts.json`: ì…ë ¥ í”„ë¡¬í”„íŠ¸
- `learned_prompts.json`: í•™ìŠµëœ ì»¨í…ìŠ¤íŠ¸ ë²¡í„° ë° ì„ë² ë”©

---

## ğŸ“Š í•™ìŠµ ê²°ê³¼ í•´ì„

### TensorBoard í™•ì¸

```bash
tensorboard --logdir=./output/video_feature_coop/tensorboard
```

**ëª¨ë‹ˆí„°ë§ í•­ëª©:**
- Training Loss: ê°ì†Œ ì¶”ì´ í™•ì¸
- Validation Accuracy: ìˆ˜ë ´ í™•ì¸
- Learning Rate: ìŠ¤ì¼€ì¤„ëŸ¬ ë™ì‘ í™•ì¸

### ë©”íŠ¸ë¦­ ë¶„ì„

#### í‘œì¤€ í‰ê°€ ê²°ê³¼ (metrics.json)

```json
{
  "frame_level": {
    "accuracy": 0.8234,
    "macro_f1": 0.7891,
    "per_class": {
      "Normal": {"precision": 0.92, "recall": 0.88, "f1": 0.90},
      "Abuse": {"precision": 0.85, "recall": 0.82, "f1": 0.835}
    }
  },
  "video_level": {
    "accuracy": 0.8901
  }
}
```

**í•´ì„:**
- **Accuracy > 0.80**: ìš°ìˆ˜
- **Accuracy > 0.70**: ì–‘í˜¸
- **Accuracy < 0.60**: ì¬í•™ìŠµ ê¶Œì¥

#### Temporal GT í‰ê°€ ê²°ê³¼

```json
{
  "multi_class": {
    "accuracy": 0.8234
  },
  "binary_anomaly_detection": {
    "accuracy": 0.8901,
    "auc_roc": 0.9234,
    "auc_pr": 0.9156
  },
  "anomaly_only": {
    "auc_roc": 0.8934
  }
}
```

**ë°°í¬ ê¸°ì¤€:**
- AUC-ROC > 0.90
- Recall > 0.85 (ì´ìƒ ë†“ì¹˜ì§€ ì•ŠìŒ)
- Precision > 0.80 (ì˜¤ê²½ë³´ ìµœì†Œí™”)
- Accuracy > 0.85

---

## ğŸ› ë¬¸ì œ í•´ê²°

### í•™ìŠµì´ ìˆ˜ë ´í•˜ì§€ ì•ŠìŒ (Loss ê³ ì •, Accuracy 1%)

**ì›ì¸ ë¶„ì„:**
- EOT ìœ„ì¹˜ collapse (ì´ë¯¸ í•´ê²°ë¨ - mean poolingìœ¼ë¡œ ë³€ê²½)
- Device mismatch (ì´ë¯¸ í•´ê²°ë¨ - buffer ë“±ë¡)
- Learning rate ë„ˆë¬´ ë†’ìŒ

**í•´ê²°ì±…:**
```bash
# Learning rate ê°ì†Œ
python train_video_feature_coop.py ... --lr 0.0005

# ë” ë§ì€ ì—í¬í¬
python train_video_feature_coop.py ... --epochs 100

# ë” ë§ì€ context tokens
python train_video_feature_coop.py ... --n-ctx 32
```

### ë©”ëª¨ë¦¬ ë¶€ì¡± (OOM)

```bash
# ë°°ì¹˜ í¬ê¸° ê°ì†Œ
python train_video_feature_coop.py ... --batch-size 16

# ì›Œì»¤ ê°ì†Œ
python train_video_feature_coop.py ... --num-workers 2
```

### í‰ê°€ ì‹œ Video ID ë§¤ì¹­ ì‹¤íŒ¨

**ì›ì¸:** ë°ì´í„°ì…‹ íŒŒì¼ëª…ê³¼ ì–´ë…¸í…Œì´ì…˜ íŒŒì¼ëª… ë¶ˆì¼ì¹˜

**í•´ê²°ì±…:**
- ì–´ë…¸í…Œì´ì…˜ íŒŒì¼ì˜ ë¹„ë””ì˜¤ ì´ë¦„ í™•ì¸
- `_x264`, `.mp4` ì ‘ë¯¸ì‚¬ í™•ì¸
- í‰ê°€ ìŠ¤í¬ë¦½íŠ¸ê°€ ìë™ìœ¼ë¡œ ì •ê·œí™”í•¨

---

## ğŸ“ˆ ê¶Œì¥ ì›Œí¬í”Œë¡œìš°

### 1. ê¸°ë³¸ ëª¨ë¸ í•™ìŠµ

```bash
# ê¸°ë³¸ ì„¤ì •ìœ¼ë¡œ í•™ìŠµ
python train_video_feature_coop.py \
    --feature-dir /path/to/train \
    --val-feature-dir /path/to/val \
    --epochs 50 \
    --output-dir ./output/baseline
```

### 2. ì„±ëŠ¥ í‰ê°€

```bash
python evaluate_video_feature_coop.py \
    --test-feature-dir /path/to/test \
    --checkpoint-path ./output/baseline/video_feature_coop_best.pth \
    --output-dir ./output/eval_baseline
```

### 3. ì»¤ìŠ¤í…€ í”„ë¡¬í”„íŠ¸ ì‹¤í—˜

```bash
# í”„ë¡¬í”„íŠ¸ ì„¤ê³„
nano custom_prompts_v1.json

# í•™ìŠµ
python custom_prompt_training.py \
    --feature-dir /path/to/train \
    --val-feature-dir /path/to/val \
    --initial-prompts-file ./custom_prompts_v1.json \
    --output-dir ./output/custom_v1

# í‰ê°€
python evaluate_video_feature_coop.py \
    --test-feature-dir /path/to/test \
    --checkpoint-path ./output/custom_v1/checkpoints/best_model.pth \
    --output-dir ./output/eval_custom_v1
```

### 4. ê²°ê³¼ ë¹„êµ

```python
import json

# Baseline ê²°ê³¼
with open('./output/eval_baseline/metrics.json') as f:
    baseline = json.load(f)

# Custom ê²°ê³¼
with open('./output/eval_custom_v1/metrics.json') as f:
    custom = json.load(f)

# ë¹„êµ
print(f"Baseline Acc: {baseline['frame_level']['accuracy']:.4f}")
print(f"Custom Acc: {custom['frame_level']['accuracy']:.4f}")
print(f"Improvement: {custom['frame_level']['accuracy'] - baseline['frame_level']['accuracy']:+.4f}")
```

### 5. í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” (ì„ íƒ)

ì„±ëŠ¥ì´ ë¶€ì¡±í•˜ë©´:

```bash
# Context tokens ì¦ê°€
python custom_prompt_training.py ... --n-ctx 32

# Learning rate ì¡°ì •
python custom_prompt_training.py ... --lr 0.001

# ë” ê¸´ í•™ìŠµ
python custom_prompt_training.py ... --epochs 100
```

---

## ğŸ” ê³ ê¸‰ ì‚¬ìš©ë²•

### ë¹„ë””ì˜¤ ë ˆë²¨ Mean Pooling

```bash
# í•™ìŠµ: [T, D] â†’ [D]ë¡œ ì§‘ê³„
python train_video_feature_coop.py \
    --feature-dir /path/to/train \
    --val-feature-dir /path/to/val \
    --use-video-level-pooling \
    --output-dir ./output/video_pooling

# í‰ê°€: ë™ì¼í•˜ê²Œ ì§€ì •
python evaluate_video_feature_coop.py \
    --test-feature-dir /path/to/test \
    --checkpoint-path ./output/video_pooling/video_feature_coop_best.pth \
    --use-video-level-pooling
```

### Temporal Ground Truth ê¸°ë°˜ í‰ê°€

```bash
python evaluate_with_temporal_gt.py \
    --test-feature-dir /path/to/test \
    --annotation-file ./annotation/Temporal_Anomaly_Annotation.txt \
    --checkpoint-path ./output/baseline/video_feature_coop_best.pth \
    --fps 25 \
    --output-dir ./output/eval_temporal
```

### í•™ìŠµëœ í”„ë¡¬í”„íŠ¸ ë¶„ì„

```python
import json
import numpy as np

with open('./output/custom_v1/learned_prompts.json') as f:
    learned = json.load(f)

for classname, data in learned.items():
    ctx = np.array(data['context_vector'])
    print(f"{classname}:")
    print(f"  Shape: {data['context_shape']}")
    print(f"  L2 norm: {np.linalg.norm(ctx):.4f}")
```

---

## ğŸ“‹ ì²´í¬ë¦¬ìŠ¤íŠ¸

### ë°°í¬ ì „ í™•ì¸ì‚¬í•­

- [ ] **í•™ìŠµ ì™„ë£Œ**
  - [ ] Loss ê°ì†Œ í™•ì¸
  - [ ] Validation accuracy ìˆ˜ë ´
  - [ ] ì²´í¬í¬ì¸íŠ¸ ì €ì¥ë¨

- [ ] **í‰ê°€ ê²°ê³¼**
  - [ ] Frame-level accuracy > 0.70
  - [ ] Video-level accuracy > 0.80
  - [ ] Per-class F1 ëª¨ë‘ > 0.60

- [ ] **Temporal GT í‰ê°€** (í•´ë‹¹ ì‹œ í•„ìˆ˜)
  - [ ] Multi-class accuracy > 0.80
  - [ ] Binary AUC-ROC > 0.90
  - [ ] Recall > 0.85

- [ ] **í˜¼ë™í–‰ë ¬ ë¶„ì„**
  - [ ] ë¹„ì •ìƒì  íŒ¨í„´ ì—†ìŒ
  - [ ] íŠ¹ì • í´ë˜ìŠ¤ í¸í–¥ ì—†ìŒ

---

## ğŸ“š ì¶”ê°€ ë¦¬ì†ŒìŠ¤

### ë¬¸ì„œ
- [CUSTOM_PROMPT_TRAINING.md](./CUSTOM_PROMPT_TRAINING.md) - ì»¤ìŠ¤í…€ í”„ë¡¬í”„íŠ¸ ìƒì„¸ ê°€ì´ë“œ
- [EVALUATION_GUIDE.md](./EVALUATION_GUIDE.md) - í‘œì¤€ í‰ê°€ ê°€ì´ë“œ
- [TEMPORAL_GT_EVALUATION.md](./TEMPORAL_GT_EVALUATION.md) - Temporal GT í‰ê°€ ê°€ì´ë“œ
- [QUICKSTART_EVALUATION.md](./QUICKSTART_EVALUATION.md) - ë¹ ë¥¸ ì‹œì‘

### ì˜ˆì œ
- [custom_prompts_example.json](./custom_prompts_example.json) - í”„ë¡¬í”„íŠ¸ ì˜ˆì‹œ
- [example_custom_prompt_workflow.py](./example_custom_prompt_workflow.py) - ì „ì²´ ì›Œí¬í”Œë¡œìš° ì˜ˆì œ

### ì½”ë“œ
- [datasets/video_features.py](./datasets/video_features.py) - ë°ì´í„°ì…‹
- [trainers/video_feature_coop.py](./trainers/video_feature_coop.py) - ëª¨ë¸
- [train_video_feature_coop.py](./train_video_feature_coop.py) - í•™ìŠµ
- [custom_prompt_training.py](./custom_prompt_training.py) - ì»¤ìŠ¤í…€ í”„ë¡¬í”„íŠ¸
- [evaluate_video_feature_coop.py](./evaluate_video_feature_coop.py) - í‰ê°€
- [evaluate_with_temporal_gt.py](./evaluate_with_temporal_gt.py) - Temporal GT í‰ê°€

---

## ğŸ“ ìì£¼ ë¬»ëŠ” ì§ˆë¬¸

**Q: ê¸°ë³¸ í•™ìŠµê³¼ ì»¤ìŠ¤í…€ í”„ë¡¬í”„íŠ¸ í•™ìŠµì˜ ì°¨ì´ëŠ”?**

A: ê¸°ë³¸ í•™ìŠµì€ ìë™ ìƒì„± í”„ë¡¬í”„íŠ¸("a video with {class}")ë¡œ ì‹œì‘, ì»¤ìŠ¤í…€ í•™ìŠµì€ ì‚¬ìš©ìê°€ ì •ì˜í•œ êµ¬ì²´ì  í”„ë¡¬í”„íŠ¸ë¡œ ì‹œì‘. ì»¤ìŠ¤í…€ í”„ë¡¬í”„íŠ¸ê°€ ì¢‹ìœ¼ë©´ ìˆ˜ë ´ì´ ë¹ ë¥´ê³  ì„±ëŠ¥ì´ í–¥ìƒë  ìˆ˜ ìˆìŒ.

**Q: V1ê³¼ V2 MobileCLIPì˜ ì°¨ì´ëŠ”?**

A: v1ì€ mobileclip íŒ¨í‚¤ì§€, v2ëŠ” open_clipì—ì„œ ë¡œë“œ. ì½”ë“œì—ì„œ ìë™ìœ¼ë¡œ detectioní•˜ê³  ì§€ì›.

**Q: í‰ê°€í•  ë•Œ ì–´ë–¤ ë©”íŠ¸ë¦­ì„ ë´ì•¼ í•˜ë‚˜?**

A:
- ì¼ë°˜ì : Video-level Accuracy
- ì´ìƒ íƒì§€: Binary AUC-ROC
- í´ë˜ìŠ¤ ë¶ˆê· í˜•: Anomaly-only AUC
- ìƒì„¸ ë¶„ì„: Confusion matrix

**Q: ì»¤ìŠ¤í…€ í”„ë¡¬í”„íŠ¸ë¥¼ ì–´ë–»ê²Œ ì“°ë‚˜ìš”?**

A:
1. JSON íŒŒì¼ ì¤€ë¹„ (custom_prompts.json)
2. custom_prompt_training.py ì‹¤í–‰
3. learned_prompts.jsonì—ì„œ ìµœì¢… ë²¡í„° í™•ì¸

---

## ë¼ì´ì„ ìŠ¤

MIT License

## ê¸°ì—¬

ì´ìŠˆ ë° PR í™˜ì˜í•©ë‹ˆë‹¤!
